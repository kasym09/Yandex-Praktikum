{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Промежуточный-Вывод\" data-toc-modified-id=\"Промежуточный-Вывод-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Промежуточный Вывод</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LGBMClassifier</a></span></li></ul></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Промежутоный-Вывод\" data-toc-modified-id=\"Промежутоный-Вывод-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Промежутоный Вывод</a></span></li><li><span><a href=\"#Тестируем-модели\" data-toc-modified-id=\"Тестируем-модели-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Тестируем модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>LGBMClassifier</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eli5 in c:\\users\\user\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: attrs>17.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (22.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (1.10.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (1.2.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (0.20.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from eli5) (0.8.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2>=3.0.0->eli5) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->eli5) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->eli5) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (8.1.11)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (1.10.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "                                              0.0/12.8 MB ? eta -:--:--\n",
      "                                              0.0/12.8 MB 2.0 MB/s eta 0:00:07\n",
      "                                             0.1/12.8 MB 919.0 kB/s eta 0:00:14\n",
      "                                              0.1/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "                                              0.2/12.8 MB 1.4 MB/s eta 0:00:10\n",
      "                                              0.3/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     -                                        0.4/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     -                                        0.5/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "     --                                       0.7/12.8 MB 1.9 MB/s eta 0:00:07\n",
      "     --                                       0.8/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     ---                                      1.1/12.8 MB 2.3 MB/s eta 0:00:06\n",
      "     ---                                      1.3/12.8 MB 2.4 MB/s eta 0:00:05\n",
      "     ----                                     1.4/12.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ----                                     1.6/12.8 MB 2.6 MB/s eta 0:00:05\n",
      "     -----                                    1.7/12.8 MB 2.7 MB/s eta 0:00:05\n",
      "     ------                                   2.0/12.8 MB 2.8 MB/s eta 0:00:04\n",
      "     ------                                   2.2/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     -------                                  2.4/12.8 MB 3.0 MB/s eta 0:00:04\n",
      "     --------                                 2.6/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     --------                                 2.8/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ---------                                3.1/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ----------                               3.3/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ----------                               3.5/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     -----------                              3.7/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------                             3.9/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     -------------                            4.2/12.8 MB 3.6 MB/s eta 0:00:03\n",
      "     -------------                            4.5/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     --------------                           4.7/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ---------------                          4.9/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ----------------                         5.3/12.8 MB 3.9 MB/s eta 0:00:02\n",
      "     -----------------                        5.5/12.8 MB 3.9 MB/s eta 0:00:02\n",
      "     ------------------                       5.8/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------                      6.1/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     -------------------                      6.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------                     6.7/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ---------------------                    7.0/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ----------------------                   7.3/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     -----------------------                  7.6/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------------                 7.9/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     -------------------------                8.2/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------------------               8.6/12.8 MB 4.6 MB/s eta 0:00:01\n",
      "     ----------------------------             9.0/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     -----------------------------            9.3/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------------------           9.6/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------          10.0/12.8 MB 4.8 MB/s eta 0:00:01\n",
      "     --------------------------------         10.4/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ----------------------------------       10.9/12.8 MB 5.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.2/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      11.5/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------------    12.0/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     --------------------------------------   12.2/12.8 MB 6.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.11)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "\u001b[38;5;3m[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use\n",
      "the full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install spacy\n",
    "!{sys.executable} -m spacy download en\n",
    "\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = 'D:\\DDownloads/toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1, parse_dates=[0], index_col=[0])\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2, parse_dates=[0], index_col=[0])\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35917</th>\n",
       "      <td>Which page? The VDV one?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78991</th>\n",
       "      <td>See also Talk:Hamas#Intro for current negociat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117232</th>\n",
       "      <td>This isn't a lie.  this is the truth. Many ben...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155952</th>\n",
       "      <td>SOCK PUPPET MY A**. YOU IZAN ARMY OF WIKI USER...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8426</th>\n",
       "      <td>\"\\n\\nwhere are my insults? heres an insult for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76330</th>\n",
       "      <td>\"\\nI agree. It does seem like a copy and paste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66725</th>\n",
       "      <td>See! this sums up your wiki and admin of wiki ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79766</th>\n",
       "      <td>, since you've brought this issue up, it would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>\"\\n After looking at a few sources it seems th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124666</th>\n",
       "      <td>You're right Joseph.. You asked me a question ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "35917                            Which page? The VDV one?      0\n",
       "78991   See also Talk:Hamas#Intro for current negociat...      0\n",
       "117232  This isn't a lie.  this is the truth. Many ben...      0\n",
       "155952  SOCK PUPPET MY A**. YOU IZAN ARMY OF WIKI USER...      1\n",
       "8426    \"\\n\\nwhere are my insults? heres an insult for...      1\n",
       "76330   \"\\nI agree. It does seem like a copy and paste...      0\n",
       "66725   See! this sums up your wiki and admin of wiki ...      1\n",
       "79766   , since you've brought this issue up, it would...      0\n",
       "6176    \"\\n After looking at a few sources it seems th...      0\n",
       "124666  You're right Joseph.. You asked me a question ...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.310497114027363"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*(df.toxic.value_counts()[1] / df.toxic.value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.toxic.value_counts().plot(kind='bar', figsize=(8, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присутсвует сильный дизбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "дубликатов нету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [00:10<00:00, 14641.91it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['text'] = df['text'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>and i really do not think you understand i cam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       explanation why the edits made under my userna...      0\n",
       "1       d aww he matches this background colour i am s...      0\n",
       "2       hey man i am really not trying to edit war it ...      0\n",
       "3       more i cannot make any real suggestions on imp...      0\n",
       "4       you sir are my hero any chance you remember wh...      0\n",
       "...                                                   ...    ...\n",
       "159446  and for the second time of asking when your vi...      0\n",
       "159447  you should be ashamed of yourself that is a ho...      0\n",
       "159448  spitzer umm theres no actual article for prost...      0\n",
       "159449  and it looks like it was actually you who put ...      0\n",
       "159450  and i really do not think you understand i cam...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [20:50<00:00, 127.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "def spacy_lemm(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['lemm_text'] = df['text'].progress_apply(spacy_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour I be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I be really not try to edit war it jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cannot make any real suggestions on imp...</td>\n",
       "      <td>0</td>\n",
       "      <td>more I can not make any real suggestion on imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there s no actual article for pros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>and i really do not think you understand i cam...</td>\n",
       "      <td>0</td>\n",
       "      <td>and I really do not think you understand I com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       explanation why the edits made under my userna...      0   \n",
       "1       d aww he matches this background colour i am s...      0   \n",
       "2       hey man i am really not trying to edit war it ...      0   \n",
       "3       more i cannot make any real suggestions on imp...      0   \n",
       "4       you sir are my hero any chance you remember wh...      0   \n",
       "...                                                   ...    ...   \n",
       "159446  and for the second time of asking when your vi...      0   \n",
       "159447  you should be ashamed of yourself that is a ho...      0   \n",
       "159448  spitzer umm theres no actual article for prost...      0   \n",
       "159449  and it looks like it was actually you who put ...      0   \n",
       "159450  and i really do not think you understand i cam...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       explanation why the edit make under my usernam...  \n",
       "1       d aww he match this background colour I be see...  \n",
       "2       hey man I be really not try to edit war it jus...  \n",
       "3       more I can not make any real suggestion on imp...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159446  and for the second time of ask when your view ...  \n",
       "159447  you should be ashamed of yourself that be a ho...  \n",
       "159448  spitzer umm there s no actual article for pros...  \n",
       "159449  and it look like it be actually you who put on...  \n",
       "159450  and I really do not think you understand I com...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный Вывод\n",
    "\n",
    "В датасете содержится 159571 строка. В данных отсутствуют дубликаты и пропущенные значения. Два столбца наиболее важны: \"toxic\" и \"text\". Столбец \"text\" содержит текстовые записи, представляющие собой твиты. Столбец \"toxic\" содержит булевые значения, указывающие, является ли каждый твит токсичным или нет. Замечено, что около 90% твитов не имеют токсичного содержания. В ходе предобработки текстов с использованием регулярных выражений были подготовлены данные для последующего анализа.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('toxic', axis=1)\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, test_size = 0.3,\n",
    "                                                                            random_state=RANDOM_STATE,\n",
    "                                                                            stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в target_train по классам: [100174  11330]\n",
      "Количество строк в target_test по классам: [42932  4856]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество строк в target_train по классам: {np.bincount(target_train)}\")\n",
    "print(f\"Количество строк в target_test по классам: {np.bincount(target_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим количество кроссвалидаций до 3 из-за размера выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_counts = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words='english')),\n",
    "    ('clf', LogisticRegression(random_state=RANDOM_STATE, max_iter=2000))])\n",
    "\n",
    "lr_params = {'clf__C': [10],\n",
    "          'clf__class_weight': ['balanced']}\n",
    "\n",
    "lr_grid = GridSearchCV(estimator=lr_pipe, param_grid=lr_params, cv=cv_counts, scoring='f1', n_jobs=-1)\n",
    "lr_grid.fit(features_train['lemm_text'], target_train)\n",
    "lr_best_paramms = lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10, 'clf__class_weight': 'balanced'}\n",
      "0.7744551363156931\n"
     ]
    }
   ],
   "source": [
    "print(lr_best_paramms)\n",
    "print(lr_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 7.229122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764062\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 22392\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101611 -> initscore=-2.179455\n",
      "[LightGBM] [Info] Start training from score -2.179455\n",
      "CPU times: total: 4min 20s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=3, max_df=0.9, use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, stop_words='english')),\n",
    "    ('clf', LGBMClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "lgb_params = {\n",
    "  'clf__n_estimators': [200],\n",
    "  'clf__learning_rate': [0.25],\n",
    "  'clf__max_depth': [-1]}\n",
    "\n",
    "lgb_grid = GridSearchCV(estimator=lgb_pipe, param_grid=lgb_params, cv=cv_counts, scoring='f1', n_jobs=-1)\n",
    "lgb_grid.fit(features_train['lemm_text'], target_train)\n",
    "lgb_best_params = lgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры:  {'clf__learning_rate': 0.25, 'clf__max_depth': -1, 'clf__n_estimators': 200}\n",
      "0.7698041732641386\n"
     ]
    }
   ],
   "source": [
    "print('Оптимальные параметры: ', lgb_best_params)\n",
    "print(lgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 31s\n",
      "Wall time: 12min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#долго грузит ячейка, возможно нужно будет сократитть гиперпараметры\n",
    "\n",
    "\n",
    "# Создание пайплайна для DecisionTreeClassifier\n",
    "dt_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, use_idf=1, smooth_idf=1, sublinear_tf=1, stop_words='english')),\n",
    "    ('clf', DecisionTreeClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Задание параметров для поиска по сетке\n",
    "dt_params = {\n",
    "    'clf__max_depth': [None],\n",
    "    'clf__min_samples_split': [2, 5],\n",
    "    'clf__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Поиск по сетке для модели DecisionTreeClassifier\n",
    "dt_grid = GridSearchCV(estimator=dt_pipe, param_grid=dt_params, cv=cv_counts, scoring='f1', n_jobs=-1)\n",
    "dt_grid.fit(features_train['lemm_text'], target_train)\n",
    "dt_best_params = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры:  {'clf__class_weight': 'balanced', 'clf__max_depth': None, 'clf__min_samples_split': 5}\n",
      "0.6256893988161175\n"
     ]
    }
   ],
   "source": [
    "print('Оптимальные параметры: ', dt_best_params)\n",
    "print(dt_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.774455</td>\n",
       "      <td>{'clf__C': 10, 'clf__class_weight': 'balanced'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.769804</td>\n",
       "      <td>{'clf__learning_rate': 0.25, 'clf__max_depth':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.625689</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__max_de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1 Score  \\\n",
       "0  Logistic Regression  0.774455   \n",
       "1             LightGBM  0.769804   \n",
       "2        Decision Tree  0.625689   \n",
       "\n",
       "                                         Best Params  \n",
       "0    {'clf__C': 10, 'clf__class_weight': 'balanced'}  \n",
       "1  {'clf__learning_rate': 0.25, 'clf__max_depth':...  \n",
       "2  {'clf__class_weight': 'balanced', 'clf__max_de...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Результаты поиска по сетке для каждой модели\n",
    "results = [\n",
    "    {'Model': 'Logistic Regression', 'F1 Score': lr_grid.best_score_, 'Best Params': lr_best_paramms},\n",
    "    {'Model': 'LightGBM', 'F1 Score': lgb_grid.best_score_, 'Best Params': lgb_best_params},\n",
    "    {'Model': 'Decision Tree', 'F1 Score': dt_grid.best_score_, 'Best Params': dt_best_params},\n",
    "    \n",
    "]\n",
    "\n",
    "# Создание DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежутоный Вывод\n",
    " Итак, все наши модели кроме DecisionTreeClassifier показали достойный результат, выше 0.75 что соответсвует требованиям. Так же я хотел задействовать модель случайного леса, но модель обучалась так долго что мой ноут завис и я не смог его выключить. теперь протестируем 2наши лучшие  модели с лучшими гиперпараметрами  на тестовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score на тестовых данных (Logistic Regression): 0.7794519162706036\n",
      "Время обучения модели 33.73616552352905\n",
      "Время предсказания модели 9.70903468132019\n"
     ]
    }
   ],
   "source": [
    "# Создание пайплайна для LogisticRegression\n",
    "lr_pipe_best = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, use_idf=1,\n",
    "                              smooth_idf=1, sublinear_tf=1, stop_words='english')),\n",
    "    ('clf', LogisticRegression(C=10, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Обучение модели LogisticRegression на обучающих данных\n",
    "start_time_train = time.time()\n",
    "lr_pipe_best.fit(features_train['lemm_text'], target_train)\n",
    "end_time_train = time.time()\n",
    "\n",
    "lr_pipe_time = end_time_train - start_time_train\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "start_time = time.time()\n",
    "lr_predictions = lr_pipe_best.predict(features_test['lemm_text'])\n",
    "end_time = time.time()\n",
    "\n",
    "prediction_time_lr = end_time - start_time\n",
    "\n",
    "# Вычисление меры F1 на тестовых данных\n",
    "f1_lr = f1_score(target_test, lr_predictions)\n",
    "\n",
    "print(\"F1 Score на тестовых данных (Logistic Regression):\", f1_lr)\n",
    "print('Время обучения модели' ,lr_pipe_time)\n",
    "print('Время предсказания модели' ,prediction_time_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова и их коэффициенты важности для классификации (Logistic Regression):\n",
      "fuck: 40.71273207005088\n",
      "fucking: 30.477807259152176\n",
      "shit: 28.13194063571821\n",
      "idiot: 27.703624428387936\n",
      "stupid: 25.18419810776293\n",
      "bullshit: 23.55981025700596\n",
      "suck: 22.522902033789254\n",
      "asshole: 22.09718276245302\n",
      "ass: 21.934253554032416\n",
      "bitch: 21.72632099633147\n",
      "faggot: 19.401317523610743\n",
      "moron: 19.158492078852134\n",
      "dick: 19.09821485915939\n",
      "cunt: 18.456457939251763\n",
      "crap: 18.346184060531094\n",
      "jerk: 15.880100006080168\n",
      "pathetic: 15.240301516171023\n",
      "penis: 15.230051228238345\n",
      "bastard: 15.18448591270869\n",
      "nigger: 14.001878952051676\n",
      "idiotic: 13.85238938921949\n",
      "loser: 13.752123887709228\n",
      "gay: 13.238078534803652\n",
      "hell: 13.206630101171553\n",
      "cock: 12.485664895684947\n",
      "fucker: 12.378043246912652\n",
      "dickhead: 11.842402439169948\n",
      "dumb: 11.831359308362106\n",
      "motherfucker: 11.638492949699529\n",
      "shut: 11.60182069574648\n",
      "ignorant: 11.593725394480341\n",
      "dumbass: 11.445875412646574\n",
      "damn: 11.367500158504598\n",
      "pussy: 11.22999842522631\n",
      "retarded: 11.151611660441889\n",
      "racist: 10.411161598660083\n",
      "liar: 10.316528502208056\n",
      "fag: 10.298605873793333\n",
      "piss: 10.255404071679557\n",
      "moronic: 10.188981608041884\n",
      "fuckin: 9.999211485252555\n",
      "jackass: 9.958323709774874\n",
      "whore: 9.9456084126919\n",
      "ck: 9.938779106897739\n",
      "hate: 9.911752843835002\n",
      "stink: 9.822248178955437\n",
      "retard: 9.756162926655893\n",
      "coward: 9.70998238378956\n",
      "scum: 9.680244864781988\n",
      "wtf: 9.66659086119305\n"
     ]
    }
   ],
   "source": [
    "# Получение списка слов после векторизации\n",
    "feature_names_lr = lr_pipe_best.named_steps['tfidf'].get_feature_names_out().tolist()\n",
    "\n",
    "# Получение коэффициентов важности для логистической регрессии\n",
    "coef_lr = lr_pipe_best.named_steps['clf'].coef_.tolist()[0]\n",
    "\n",
    "# Соединение слов и коэффициентов важности\n",
    "words_and_importances = list(zip(feature_names_lr, coef_lr))\n",
    "\n",
    "# Сортировка по абсолютному значению коэффициентов важности\n",
    "sorted_words_and_importances = sorted(words_and_importances, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Слова и их коэффициенты важности для классификации (Logistic Regression):\")\n",
    "for word, importance in sorted_words_and_importances[:50]:\n",
    "    print(f\"{word}: {importance}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11330, number of negative: 100174\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 10.712802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 764062\n",
      "[LightGBM] [Info] Number of data points in the train set: 111504, number of used features: 22392\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101611 -> initscore=-2.179455\n",
      "[LightGBM] [Info] Start training from score -2.179455\n",
      "F1 Score на тестовых данных (LGBMClassifier): 0.7732358986069878\n",
      "Время обучения модели 91.4846920967102\n",
      "Время предсказания модели 8.468631267547607\n"
     ]
    }
   ],
   "source": [
    "best_lgb_pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_df=0.9, use_idf=1,\n",
    "                              smooth_idf=1, sublinear_tf=1, stop_words='english')),\n",
    "    ('clf', LGBMClassifier(learning_rate=0.25, max_depth=-1, n_estimators=200, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# Обучение модели на обучающей выборке\n",
    "start_time_train = time.time()\n",
    "best_lgb_pipe.fit(features_train['lemm_text'], target_train)\n",
    "end_time_train = time.time()\n",
    "\n",
    "lgb_pipe_time = end_time_train - start_time_train\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "start_time = time.time()\n",
    "lgb_predictions = best_lgb_pipe.predict(features_test['lemm_text'])\n",
    "end_time = time.time()\n",
    "\n",
    "prediction_time_lgb = end_time - start_time\n",
    "\n",
    "# Вычисление меры F1\n",
    "f1_lgb = f1_score(target_test, lgb_predictions)\n",
    "\n",
    "print(\"F1 Score на тестовых данных (LGBMClassifier):\", f1_lgb)\n",
    "print('Время обучения модели' ,lgb_pipe_time)\n",
    "print('Время предсказания модели' ,prediction_time_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее важные слова и их важности для классификации:\n",
      "shit: 29\n",
      "stupid: 29\n",
      "idiot: 28\n",
      "fuck: 28\n",
      "article: 24\n",
      "hell: 21\n",
      "suck: 21\n",
      "fucking: 21\n",
      "crap: 21\n",
      "moron: 20\n",
      "asshole: 19\n",
      "bullshit: 19\n",
      "dick: 18\n",
      "cunt: 17\n",
      "just: 17\n",
      "bitch: 17\n",
      "gay: 17\n",
      "think: 16\n",
      "ass: 16\n",
      "kill: 16\n",
      "faggot: 16\n",
      "nazi: 16\n",
      "pathetic: 15\n",
      "racist: 15\n",
      "jerk: 15\n",
      "penis: 15\n",
      "die: 15\n",
      "damn: 14\n",
      "hate: 14\n",
      "say: 14\n",
      "page: 14\n",
      "stop: 14\n",
      "wikipedia: 14\n",
      "block: 14\n",
      "nigger: 13\n",
      "like: 13\n",
      "dumb: 13\n",
      "retarded: 13\n",
      "talk: 13\n",
      "remove: 13\n",
      "shut: 13\n",
      "loser: 12\n",
      "make: 12\n",
      "bastard: 12\n",
      "fool: 12\n",
      "good: 12\n",
      "point: 12\n",
      "know: 12\n",
      "ignorant: 12\n",
      "motherfucker: 11\n"
     ]
    }
   ],
   "source": [
    "# Получение списка слов после векторизации\n",
    "feature_names = best_lgb_pipe.named_steps['tfidf'].get_feature_names_out().tolist()\n",
    "\n",
    "# Вывод наиболее важных слов\n",
    "important_words = [feature_names[i] for i in np.argsort(best_lgb_pipe.named_steps['clf'].feature_importances_)[::-1]]\n",
    "important_importances = [best_lgb_pipe.named_steps['clf'].feature_importances_[i] for i in np.argsort(best_lgb_pipe.named_steps['clf'].feature_importances_)[::-1]]\n",
    "\n",
    "print(\"Наиболее важные слова и их важности для классификации:\")\n",
    "for word, importance in zip(important_words[:50], important_importances[:50]):\n",
    "    print(f\"{word}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier я не стал тестировать так как у меня в черновике она показала результат 0.71, а время обучения 11 минут что не соответсвует нашим ожиданиям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Train Time (s)</th>\n",
       "      <th>Prediction Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.779452</td>\n",
       "      <td>33.736166</td>\n",
       "      <td>9.709035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.773236</td>\n",
       "      <td>91.484692</td>\n",
       "      <td>8.468631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  F1 Score  Train Time (s)  Prediction Time (s)\n",
       "0  Logistic Regression  0.779452       33.736166             9.709035\n",
       "1             LightGBM  0.773236       91.484692             8.468631"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = [\n",
    "    {'Model': 'Logistic Regression', 'F1 Score': f1_lr, 'Train Time (s)': lr_pipe_time, 'Prediction Time (s)': prediction_time_lr},\n",
    "    {'Model': 'LightGBM', 'F1 Score': f1_lgb, 'Train Time (s)': lgb_pipe_time, 'Prediction Time (s)': prediction_time_lgb},\n",
    "\n",
    "]\n",
    "\n",
    "# Создание DataFrame\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Вывод таблицы\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для исследования интернет-магазина \"Викишоп\" был проведен анализ, который выявил, что 90% записей не содержат токсичного контента. Мы также выполнили предварительную обработку текста с помощью регулярных выражений и подготовили данные для последующего анализа. В дальнейшем, мы выбрали три модели, создали для них пайплайны и с применением кросс-валидации нашли оптимальные гиперпараметры и оценили метрику F1. После этого мы произвели выбор лучших моделей для дальнейшего тестирования, и из них лучшей оказалась модель логистической регрессии, с результатом F1 0.77, что говорит о высокой точности предсказаний данной модели. Это означает, что модель логистической регрессии способна хорошо разделять токсичные и нетоксичные тексты, и метрика F1 в 0.77 подтверждает высокую сбалансированность между полнотой и точностью предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
